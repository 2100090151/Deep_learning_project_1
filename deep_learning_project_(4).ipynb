{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e99f18ce",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-12T10:36:53.206401Z",
          "iopub.status.busy": "2024-03-12T10:36:53.205966Z",
          "iopub.status.idle": "2024-03-12T10:41:31.519779Z",
          "shell.execute_reply": "2024-03-12T10:41:31.518277Z",
          "shell.execute_reply.started": "2024-03-12T10:36:53.206364Z"
        },
        "papermill": {
          "duration": 0.00358,
          "end_time": "2024-03-14T19:39:25.875189",
          "exception": false,
          "start_time": "2024-03-14T19:39:25.871609",
          "status": "completed"
        },
        "tags": [],
        "id": "e99f18ce"
      },
      "outputs": [],
      "source": [
        "pip install ipynbcompress"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ipynbcompress import compress\n",
        "filename = '/content/deep-learning-project (4).ipynb'\n",
        "out = '/content/compressed.ipynb'\n",
        "os.stat(filename).st_size\n",
        "compress(filename, output_filename=out, img_width=800, img_format='jpeg')\n",
        "compress(filename)\n",
        "os.stat(filename).st_size"
      ],
      "metadata": {
        "id": "DH-cjcwO2nxS"
      },
      "id": "DH-cjcwO2nxS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "125ae4ad",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-14T19:39:25.883192Z",
          "iopub.status.busy": "2024-03-14T19:39:25.882899Z",
          "iopub.status.idle": "2024-03-14T21:05:49.354805Z",
          "shell.execute_reply": "2024-03-14T21:05:49.353937Z"
        },
        "papermill": {
          "duration": 5183.478605,
          "end_time": "2024-03-14T21:05:49.357095",
          "exception": false,
          "start_time": "2024-03-14T19:39:25.878490",
          "status": "completed"
        },
        "tags": [],
        "id": "125ae4ad"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "class PlantDiseaseClassifier:\n",
        "    def __init__(self, train_path, valid_path, test_path, img_width=256, img_height=256, batch_size=32):\n",
        "        self.train_path = train_path\n",
        "        self.valid_path = valid_path\n",
        "        self.test_path = test_path\n",
        "        self.img_width = img_width\n",
        "        self.img_height = img_height\n",
        "        self.batch_size = batch_size\n",
        "        self.labels = None\n",
        "        self.train_generator = None\n",
        "        self.validation_generator = None\n",
        "        self.test_generator = None\n",
        "        self.model = None\n",
        "\n",
        "    def load_data(self):\n",
        "        train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "        self.train_generator = train_datagen.flow_from_directory(self.train_path, target_size=(self.img_width, self.img_height), batch_size=self.batch_size, class_mode='binary', shuffle=True)\n",
        "\n",
        "        validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "        self.validation_generator = validation_datagen.flow_from_directory(self.valid_path, target_size=(self.img_width, self.img_height), batch_size=self.batch_size, class_mode='binary', shuffle=False)\n",
        "\n",
        "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "        self.test_generator = test_datagen.flow_from_directory(self.test_path, target_size=(self.img_width, self.img_height), batch_size=self.batch_size, class_mode=None, shuffle=False)\n",
        "\n",
        "        self.labels = self.train_generator.class_indices\n",
        "\n",
        "    def create_model(self):\n",
        "        model = keras.Sequential([\n",
        "            keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(self.img_width, self.img_height, 3)),\n",
        "            keras.layers.MaxPooling2D((2, 2)),\n",
        "            keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "            keras.layers.MaxPooling2D((2, 2)),\n",
        "            keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "            keras.layers.MaxPooling2D((2, 2)),\n",
        "            keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
        "            keras.layers.MaxPooling2D((2, 2)),\n",
        "            keras.layers.Conv2D(512, (3, 3), activation='relu'),\n",
        "            keras.layers.MaxPooling2D((2, 2)),\n",
        "            keras.layers.Flatten(),\n",
        "            keras.layers.Dense(1568,activation=\"relu\"),\n",
        "            keras.layers.Dropout(0.5),\n",
        "            keras.layers.Dense(512, activation='relu'),\n",
        "            keras.layers.Dense(len(self.labels), activation='softmax')\n",
        "        ])\n",
        "\n",
        "        opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "        model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "        model.summary()\n",
        "        self.model = model\n",
        "\n",
        "    def train_model(self, epochs=20):\n",
        "        history = self.model.fit(self.train_generator, validation_data=self.validation_generator,epochs=epochs)\n",
        "        return history\n",
        "\n",
        "    def evaluate_model(self):\n",
        "        test_loss, test_accuracy = self.model.evaluate(self.validation_generator, steps=len(self.validation_generator))\n",
        "        print(f\"Test Loss:     {test_loss}\")\n",
        "        print(f\"Test Accuracy: {test_accuracy}\")\n",
        "    def predict(self):\n",
        "        predictions = self.model.predict(self.test_generator)\n",
        "        y_pred = np.argmax(predictions, axis=1)\n",
        "        return y_pred\n",
        "    def plot_confusion_matrix(self, y_true, y_pred):\n",
        "        confusion = confusion_matrix(y_true, y_pred)\n",
        "        sns.heatmap(confusion, annot=True, fmt='d', cmap='jet', xticklabels=self.labels.keys(), yticklabels=self.labels.keys())\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.show()\n",
        "\n",
        "    def print_classification_report(self, y_true, y_pred):\n",
        "        print(classification_report(y_true, y_pred, target_names=self.labels.keys()))\n",
        "\n",
        "# Define paths to your dataset directories\n",
        "train_path = '/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/'\n",
        "valid_path = '/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/'\n",
        "test_path = '/kaggle/input/new-plant-diseases-dataset/test/'\n",
        "\n",
        "classifier = PlantDiseaseClassifier(train_path=train_path, valid_path=valid_path, test_path=test_path)\n",
        "classifier.load_data()\n",
        "classifier.create_model()\n",
        "history = classifier.train_model(epochs=20)\n",
        "classifier.evaluate_model()\n",
        "y_pred = classifier.predict()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "241e68e2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-14T21:05:57.030984Z",
          "iopub.status.busy": "2024-03-14T21:05:57.030031Z",
          "iopub.status.idle": "2024-03-14T21:05:57.714506Z",
          "shell.execute_reply": "2024-03-14T21:05:57.713598Z"
        },
        "papermill": {
          "duration": 4.502295,
          "end_time": "2024-03-14T21:05:57.716650",
          "exception": false,
          "start_time": "2024-03-14T21:05:53.214355",
          "status": "completed"
        },
        "tags": [],
        "id": "241e68e2"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e94f96d4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-14T21:06:05.273406Z",
          "iopub.status.busy": "2024-03-14T21:06:05.272518Z",
          "iopub.status.idle": "2024-03-14T21:06:05.559014Z",
          "shell.execute_reply": "2024-03-14T21:06:05.558061Z"
        },
        "papermill": {
          "duration": 4.038894,
          "end_time": "2024-03-14T21:06:05.560889",
          "exception": false,
          "start_time": "2024-03-14T21:06:01.521995",
          "status": "completed"
        },
        "tags": [],
        "id": "e94f96d4"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42356185",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-14T21:06:13.028165Z",
          "iopub.status.busy": "2024-03-14T21:06:13.027346Z",
          "iopub.status.idle": "2024-03-14T21:06:17.267993Z",
          "shell.execute_reply": "2024-03-14T21:06:17.266900Z"
        },
        "papermill": {
          "duration": 8.051793,
          "end_time": "2024-03-14T21:06:17.315197",
          "exception": false,
          "start_time": "2024-03-14T21:06:09.263404",
          "status": "completed"
        },
        "tags": [],
        "id": "42356185"
      },
      "outputs": [],
      "source": [
        "print(y_pred)\n",
        "len(y_pred)\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "test_filenames = classifier.test_generator.filenames\n",
        "num_images = len(test_filenames)\n",
        "num_rows = int(np.ceil(num_images / 5))\n",
        "num_cols = min(num_images, 5)\n",
        "plt.figure(figsize=(15, 3 * num_rows))\n",
        "for i in range(num_images):\n",
        "    # Load and display the image\n",
        "    img_path = os.path.join(classifier.test_path, test_filenames[i])\n",
        "    img = plt.imread(img_path)\n",
        "    plt.subplot(num_rows, num_cols, i + 1)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Get the predicted label\n",
        "    pred_label_idx = y_pred[i]\n",
        "    predicted_label = list(classifier.labels.keys())[pred_label_idx]\n",
        "\n",
        "    # Print the predicted label\n",
        "    plt.title(f'Label: {os.path.basename(test_filenames[i])}\\nPredicted: {predicted_label}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d13dae9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-14T21:06:24.964439Z",
          "iopub.status.busy": "2024-03-14T21:06:24.964075Z",
          "iopub.status.idle": "2024-03-14T21:06:27.852228Z",
          "shell.execute_reply": "2024-03-14T21:06:27.851291Z"
        },
        "papermill": {
          "duration": 6.773675,
          "end_time": "2024-03-14T21:06:27.856608",
          "exception": false,
          "start_time": "2024-03-14T21:06:21.082933",
          "status": "completed"
        },
        "tags": [],
        "id": "9d13dae9"
      },
      "outputs": [],
      "source": [
        "print(\"Classification Report for Test Dataset:\")\n",
        "print(classification_report(y_pred, range(len(y_pred)), labels=range(len(classifier.labels.keys())), target_names=classifier.labels.keys()))\n",
        "sns.heatmap(confusion_matrix(range(len(y_pred)), y_pred), annot=True, fmt='d', cmap='jet', xticklabels=classifier.labels.keys(), yticklabels=classifier.labels.keys())\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix for Test Dataset')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea5d0dbc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-14T21:06:35.477287Z",
          "iopub.status.busy": "2024-03-14T21:06:35.476921Z",
          "iopub.status.idle": "2024-03-15T01:54:42.688609Z",
          "shell.execute_reply": "2024-03-15T01:54:42.687641Z"
        },
        "papermill": {
          "duration": 17298.380215,
          "end_time": "2024-03-15T01:54:49.984702",
          "exception": false,
          "start_time": "2024-03-14T21:06:31.604487",
          "status": "completed"
        },
        "tags": [],
        "id": "ea5d0dbc"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Setting up paths\n",
        "train_path = '/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/'\n",
        "test_path = '/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/'\n",
        "\n",
        "# Data augmentation and preprocessing\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_set = train_datagen.flow_from_directory(train_path,\n",
        "                                              target_size=(224, 224),\n",
        "                                              batch_size=32,\n",
        "                                              class_mode='binary')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(test_path,\n",
        "                                            target_size=(224, 224),\n",
        "                                            batch_size=32,\n",
        "                                            class_mode='binary')\n",
        "\n",
        "# Loading VGG16 model\n",
        "vgg = VGG16(input_shape=(224, 224, 3), weights='imagenet', include_top=False)\n",
        "\n",
        "# Freezing the pretrained layers\n",
        "for layer in vgg.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Adding custom layers for classification\n",
        "x = Flatten()(vgg.output)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(len(train_set.class_indices), activation='softmax')(x)\n",
        "\n",
        "# Creating the final model\n",
        "model = Model(inputs=vgg.input, outputs=predictions)\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(train_set,\n",
        "                    validation_data=test_set,\n",
        "                    epochs=20)\n",
        "\n",
        "# Plotting training and validation accuracy\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plotting training and validation loss\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05b2ef7c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-15T01:55:05.307660Z",
          "iopub.status.busy": "2024-03-15T01:55:05.307270Z",
          "iopub.status.idle": "2024-03-15T06:45:10.493212Z",
          "shell.execute_reply": "2024-03-15T06:45:10.492323Z"
        },
        "papermill": {
          "duration": 17423.745868,
          "end_time": "2024-03-15T06:45:21.300595",
          "exception": false,
          "start_time": "2024-03-15T01:54:57.554727",
          "status": "completed"
        },
        "tags": [],
        "id": "05b2ef7c"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG19  # Modified import\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Setting up paths\n",
        "train_path = '/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train/'\n",
        "test_path = '/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/'\n",
        "\n",
        "# Data augmentation and preprocessing\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_set = train_datagen.flow_from_directory(train_path,\n",
        "                                              target_size=(224, 224),  # Adjusted input shape\n",
        "                                              batch_size=32,\n",
        "                                              class_mode='binary')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(test_path,\n",
        "                                            target_size=(224, 224),  # Adjusted input shape\n",
        "                                            batch_size=32,\n",
        "                                            class_mode='binary')\n",
        "\n",
        "# Loading VGG19 model  # Modified\n",
        "vgg = VGG19(input_shape=(224, 224, 3), weights='imagenet', include_top=False)  # Modified\n",
        "\n",
        "# Freezing the pretrained layers\n",
        "for layer in vgg.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Adding custom layers for classification\n",
        "x = Flatten()(vgg.output)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(len(train_set.class_indices), activation='softmax')(x)\n",
        "\n",
        "# Creating the final model\n",
        "model = Model(inputs=vgg.input, outputs=predictions)\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(train_set,\n",
        "                    validation_data=test_set,\n",
        "                    epochs=20)\n",
        "\n",
        "# Plotting training and validation accuracy\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plotting training and validation loss\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 78313,
          "sourceId": 182633,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30664,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 39974.851877,
      "end_time": "2024-03-15T06:45:36.747980",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-03-14T19:39:21.896103",
      "version": "2.5.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}